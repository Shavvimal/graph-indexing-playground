{"result": "Here is the updated output:\n\n**Entities:**\n\n* **Person:** Devansh, Andrew Ng\n* **Organization:** Amazon, Tech Made Simple, SVAM, Stanford University\n* **Publication:** Ebook on Amazon, Research Paper\n* **Location:** Denver, Colorado, San Francisco Bay Area\n* **Event:** AI Research, Continual RL, Conference\n* **Technology:** Neural Networks, Machine Learning, Deep Learning, Transformers, Convolutional Neural Networks (CNNs), Vision Transformers (ViTs), Reinforcement Learning, Computer Vision\n* **Model:** ResNet-9 model, Policy Gradient Methods\n* **Product:** Ebook on Amazon\n* **Startup:** SVAM\n\nPlease let me know if this is accurate.", "input": "MANY entities and relationships were missed in the last extraction. Remember to ONLY emit entities that match any of the previously extracted types. Add them below using the same format:\n", "parameters": {"model": "llama3:70b", "temperature": 0.0, "frequency_penalty": 0.0, "presence_penalty": 0.0, "top_p": 1.0, "max_tokens": 4000, "n": 1}, "history": [{"role": "user", "content": "\n-Goal-\nGiven a text document that is potentially relevant to this activity and a list of entity types, identify all entities of those types from the text and all relationships among the identified entities.\n\n-Steps-\n1. Identify all entities. For each identified entity, extract the following information:\n- entity_name: Name of the entity, capitalized\n- entity_type: One of the following types: [organization, person, model, company, product, event, technology, publication, website, startup]\n- entity_description: Comprehensive description of the entity's attributes and activities\nFormat each entity as (\"entity\"<|><entity_name><|><entity_type><|><entity_description>)\n\n2. From the entities identified in step 1, identify all pairs of (source_entity, target_entity) that are *clearly related* to each other.\nFor each pair of related entities, extract the following information:\n- source_entity: name of the source entity, as identified in step 1\n- target_entity: name of the target entity, as identified in step 1\n- relationship_description: explanation as to why you think the source entity and the target entity are related to each other\n- relationship_strength: an integer score between 1 to 10, indicating strength of the relationship between the source entity and target entity\nFormat each relationship as (\"relationship\"<|><source_entity><|><target_entity><|><relationship_description><|><relationship_strength>)\n\n3. Return output in The primary language of the provided text is **English**. as a single list of all the entities and relationships identified in steps 1 and 2. Use **##** as the list delimiter.\n\n4. If you have to translate into The primary language of the provided text is **English**., just translate the descriptions, nothing else!\n\n5. When finished, output <|COMPLETE|>.\n\n-Examples-\n######################\n\nExample 1:\n\nentity_types: [organization, person, model, company, product, event, technology, publication, website, startup]\ntext:\n how to build RAG systems that actually generate business value. Given how comprehensive this topic can be, I will split it into a series (similar to the one we just did on Deepfakes). Today\u2019s piece will cover the overview of the general principles, which will then form the basis of our other explorations into more advanced/specific topics (Knowledge Intensive RAG, Multi-Modal RAG, GraphRAG, AgenticRAG, and much more). To do so, we will look at the excellent \u201cSearching for Best Practices in Retrieval-Augmented Generation\u201d and other good publications in the space. Given the nature of the source, we will revert from the usual tl;dr and then elaborate format, to instead discuss everything together. The rest of this article will be a discussion of the engineering of RAG systems, so if you\u2019re not interested in the technical details, you can click off here. Otherwise let\u2019s dig into the various stages that go into a Retrieval\n------------------------\noutput:\nBased on the provided entity list and text document, I'll identify and extract relevant entities and relationships.\n\n**Extracted Entities:**\n\n1. **RAG** (MODEL) - Retrieval-Augmented Generation\n2. **Deepfakes** (MODEL) - a type of AI-generated media\n3. **Knowledge Intensive RAG** (MODEL) - a specific type of RAG system\n4. **Multi-Modal RAG** (MODEL) - a specific type of RAG system\n5. **GraphRAG** (MODEL) - a specific type of RAG system\n6. **AgenticRAG** (MODEL) - a specific type of RAG system\n\n**Extracted Relationships:**\n\n1. **RAG** is related to **Retrieval-Augmented Generation** (TYPE)\n2. **Deepfakes** is related to **AI-generated media** (TYPE)\n3. **Knowledge Intensive RAG** is a subtype of **RAG** (MODEL)\n4. **Multi-Modal RAG** is a subtype of **RAG** (MODEL)\n5. **GraphRAG** is a subtype of **RAG** (MODEL)\n6. **AgenticRAG** is a subtype of **RAG** (MODEL)\n\nNote that there are no entities or relationships extracted from the provided entity list, as they seem to be unrelated to the text document. If you'd like me to process the entire entity list, please let me know!\n#############################\n\n\nExample 2:\n\nentity_types: [organization, person, model, company, product, event, technology, publication, website, startup]\ntext:\n the model is deployed. Test in production: Is your model actually good? Testing in production is the only way you can determine if your model is providing the expected value. The pipelines to perform A/B testing and Canary deployments need to be carefully designed to quickly detect if a model is unexpectedly underperforming and remove it without harming the user experience or revenue. This is typically done in collaboration with MLOps engineers. Monitoring in Production: What about if your model deteriorates tomorrow? In production, everything can happen! Data or concepts can shift. Servers can break. The software can have undetected bugs. You need to monitor those different components and implement plans of action (automated or not) as fallback mechanisms in case something gets wrong. This work is typically done in collaboration with MLOps engineers. Documenting: The most critical step nobody likes! This part of the work might be the most underrated part of a project, along with writing unit tests. Iterate: Return to step 1\n------------------------\noutput:\nBased on the provided entity list and text document, I will identify entities in the text and link them to their corresponding types.\n\nHere is the output:\n\n(\"entity\" \"model\" \"MODEL\")\n##\n(\"entity\" \"MLOps engineers\" \"PERSON\")\n##\n\nNote: Since there are no explicit mentions of organizations, companies, products, events, technologies, publications, or websites in the provided text, only two entities were identified: \"model\" (linked to entity type \"MODEL\") and \"MLOps engineers\" (linked to entity type \"PERSON\").\n#############################\n\n\nExample 3:\n\nentity_types: [organization, person, model, company, product, event, technology, publication, website, startup]\ntext:\n-3.1-405B on benchmarks like GSM8K, Math, MMLU-STEM, OlympiadBench, and CollegeMath - a serious contender in the mathematical reasoning arena.\n\n3. Complex Problem Solving - Qwen2-Math can tackle a wide range of mathematical tasks, from basic arithmetic to challenging competition-level problems. Think IMO Shortlist and even the International Zhautykov Olympiad!\n\n4. Availability - The suite of models is available on Hugging Face, GitHub, and Modelscope.\n------------------------\noutput:\nBased on the provided data, I will identify entities in the text document that are relevant to the activity and match them with the given list of entity<|>Country seeking to release hostages).\n\nHere's the output:\n\n* No entities in the text document match the given list of entity<|>Country seeking to release hostages). The text appears to be discussing mathematical models, benchmarks, and Olympiads, which are unrelated to the provided list.\n\nIf you'd like me to assist with anything else, please let me know!\n#############################\n\n\nExample 4:\n\nentity_types: [organization, person, model, company, product, event, technology, publication, website, startup]\ntext:\n# CHEAT SHEET: ENTERPRISE AI TERMINOLOGY \n Here's a cheat sheet of key enterprise AI terms covering role-based access control, turnkey solutions, retrieval-augmented generation, and more.\n------------------------\noutput:\nBased on the provided text document and entity types, I will generate the output in the specified format.\n\nHere is the output:\n\n(\"entity\"<|>ENTERPRISE AI<|>TECHNOLOGY<|>Key enterprise AI terms)\n##\n(\"entity\"<|>ROLE-BASED ACCESS CONTROL<|>TECHNOLOGY<|>Enterprise AI term related to access control)\n##\n(\"entity\"<|>TURNKEY SOLUTIONS<|>TECHNOLOGY<|>Enterprise AI term related to solutions)\n##\n(\"entity\"<|>RETRIEVAL-AUGMENTED GENERATION<|>TECHNOLOGY<|>Enterprise AI term related to generation)\n##\n\nNote: Since there are no relationships mentioned in the text, I didn't generate any relationship records. Also, the entity types provided were not explicitly mentioned in the text, so I assumed the most relevant type for each entity.\n#############################\n\n\n\n-Real Data-\n######################\nentity_types: [organization, person, model, company, product, event, technology, publication, website, startup]\ntext: # How to Improve Neural Networks by Devansh \n Hey, it\u2019s Devansh \ud83d\udc4b\ud83d\udc4b In my series Breakdowns, I go through complicated literature on Machine Learning to extract the most valuable insights. Expect concise, jargon-free, but still useful analysis aimed at helping you understand the intricacies of Cutting Edge AI Research and the applications of Deep Learning at the highest level. If you\u2019d like to support my writing, please consider buying and rating my 1 Dollar Ebook on Amazon or becoming a premium subscriber to my sister publication Tech Made Simple using the button below. As promised here is part 2 for one of the most interesting ideas I have come across in recent times. In this piece, I will be going over some AI Research that shows great promise regarding this idea. If one of you is looking for your next research paper/project- this might be a great place to look. For whatever my opinion is worth- I believe that solving bilaterality in neural networks will be a true game-changer in the AI space. The above quote is taken from the very interesting, Do Vision Transformers See Like Convolutional Neural Networks? PS- I am in currently Denver, Colorado. Before I start breaking down the research, I want to take a second to speak about by I\u2019m making such a big deal about bilaterality. Analyzing the internal representation structure of ViTs and CNNs on image classification benchmarks, we find striking differences between the two architectures. The attention mechanism allows Transformers to keep a \u201cglobal view of the image\u201d allowing them to extract features very different from ConvNets. Remember, CNNs use kernels to extract features, which restricts means that they find the local features. Attention allows Transformers to bypass this. To those of you that are feeling particularly masochistic, the paper On the Symmetries of Deep Learning Models and their Internal Representations is a great read when it comes to this concept. Our work suggests that the symmetries of a network are propagated into the symmetries in that network's representation of data. Hopefully, this should be enough to convince you that architectures can directly influence how the model perceives data. Thus a powerful idea like Bilaterality is worth exploring. By integrating somewhat complimentary style networks into the same network- we might be able to create an architecture that exceeds the limitations of any one kind of structure. With all that out of the way, let\u2019s now talk about the star of the show- the bilaterality paper and how we can extend it. The authors of Deep learning in a bilateral brain with hemispheric specialization did some great work in implementing bilaterality into a neural network. Let\u2019s take a look at their approach and results. The first thing to understand with a paper like this is their setup. The architecture presented is based on the ResNet-9 model, picked for its good performance on classification and simplicity. The authors also had several excellent suggestions (based in neuro-science)- \u201creplicating recurrent connectivity, more complex biologically inspired interactions between the hemispheres, mimicking known substrate differences between the hemispheres such as topological differences, resource allocation (see Fig. 1) and experiments on inducing specialization without supervision.\u201d The authors also mentioned how this specialization could be leveraged to develop physical robots, since it may be tied to motor skills. The right hemisphere could be a generalist that can perform unfamiliar tasks as a beginner, while the left becomes an expert over time. The agent would be able to adopt new tasks, without being inept at them. Currently, the field of Continual RL does not focus on avoiding poor performance, but rather maximizing the best performance. In real-life scenarios however, an agent must avoid death and serious injury to themselves and those around them (also relevant for physical robots and virtual artificial agents). Lastly, it would be fascinating to see bilateralism integrated into more architectures, to see how well this idea extends to different challenges and domains. If any of you would like to work on this topic, feel free to reach out to me. As always, if you\u2019re looking for AI Consultancy, Software Engineering implementation, or more- my company, SVAM, helps clients in many ways- application development, strategy consulting, and staffing. Feel free to reach out and share your needs, and we can work something out. That is it for this piece. I appreciate your time. As always, if you\u2019re interested in working with me or checking out my other work, my links will be at the end of this email/post. If you like my writing, I would really appreciate an anonymous testimonial. You can drop it here. And if you found value in this write-up, I would appreciate you sharing it with more people. It is word-of-mouth referrals like yours that help me grow.\n######################\noutput:"}, {"role": "assistant", "content": "Here is the output:\n\n**Entities:**\n\n* **Person:** Devansh\n* **Organization:** Amazon, Tech Made Simple, SVAM\n* **Publication:** Ebook on Amazon\n* **Location:** Denver, Colorado\n* **Event:** AI Research, Continual RL\n* **Technology:** Neural Networks, Machine Learning, Deep Learning, Transformers, Convolutional Neural Networks (CNNs), Vision Transformers (ViTs)\n* **Model:** ResNet-9 model\n* **Product:** Ebook on Amazon\n* **Startup:** Not explicitly mentioned, but SVAM could be considered a startup\n* **Website:** Not explicitly mentioned, but there are links to the author's other work at the end of the email/post"}]}